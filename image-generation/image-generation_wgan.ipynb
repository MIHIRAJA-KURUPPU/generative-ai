{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec73cf04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Starting Training Loop...\n",
      "[Epoch 0/50] Step 0/938 Loss_D: -0.0072 Loss_G: 0.0027\n",
      "[Epoch 0/50] Step 100/938 Loss_D: -1.8784 Loss_G: -1.6879\n",
      "[Epoch 0/50] Step 200/938 Loss_D: -3.6362 Loss_G: -3.8740\n",
      "[Epoch 0/50] Step 300/938 Loss_D: -3.3774 Loss_G: -4.9600\n",
      "[Epoch 0/50] Step 400/938 Loss_D: -2.7655 Loss_G: -4.6600\n",
      "[Epoch 0/50] Step 500/938 Loss_D: -2.7063 Loss_G: -3.6568\n",
      "[Epoch 0/50] Step 600/938 Loss_D: -2.2661 Loss_G: -1.0638\n",
      "[Epoch 0/50] Step 700/938 Loss_D: -2.2940 Loss_G: -3.7315\n",
      "[Epoch 0/50] Step 800/938 Loss_D: -2.0941 Loss_G: -3.1257\n",
      "[Epoch 0/50] Step 900/938 Loss_D: -2.2867 Loss_G: -4.2933\n",
      "[Epoch 1/50] Step 0/938 Loss_D: -1.6409 Loss_G: -4.4634\n",
      "[Epoch 1/50] Step 100/938 Loss_D: -2.0911 Loss_G: -4.8055\n",
      "[Epoch 1/50] Step 200/938 Loss_D: -1.8259 Loss_G: -5.6522\n",
      "[Epoch 1/50] Step 300/938 Loss_D: -1.7344 Loss_G: -4.4042\n",
      "[Epoch 1/50] Step 400/938 Loss_D: -1.5641 Loss_G: -4.7958\n",
      "[Epoch 1/50] Step 500/938 Loss_D: -1.9372 Loss_G: -7.2175\n",
      "[Epoch 1/50] Step 600/938 Loss_D: -2.2295 Loss_G: -0.6943\n",
      "[Epoch 1/50] Step 700/938 Loss_D: -2.0064 Loss_G: -4.7998\n",
      "[Epoch 1/50] Step 800/938 Loss_D: -1.5380 Loss_G: -6.4294\n",
      "[Epoch 1/50] Step 900/938 Loss_D: -1.7500 Loss_G: -5.7697\n",
      "[Epoch 2/50] Step 0/938 Loss_D: -1.2922 Loss_G: -5.6198\n",
      "[Epoch 2/50] Step 100/938 Loss_D: -1.8558 Loss_G: -3.8141\n",
      "[Epoch 2/50] Step 200/938 Loss_D: -1.8940 Loss_G: -5.8362\n",
      "[Epoch 2/50] Step 300/938 Loss_D: -1.8528 Loss_G: -7.4015\n",
      "[Epoch 2/50] Step 400/938 Loss_D: -1.8553 Loss_G: -0.8166\n",
      "[Epoch 2/50] Step 500/938 Loss_D: -1.9034 Loss_G: -4.8660\n",
      "[Epoch 2/50] Step 600/938 Loss_D: -1.6623 Loss_G: -0.4204\n",
      "[Epoch 2/50] Step 700/938 Loss_D: -1.5642 Loss_G: -5.9285\n",
      "[Epoch 2/50] Step 800/938 Loss_D: -1.5195 Loss_G: 2.6245\n",
      "[Epoch 2/50] Step 900/938 Loss_D: -1.8867 Loss_G: -0.1503\n",
      "[Epoch 3/50] Step 0/938 Loss_D: -1.3776 Loss_G: 4.9267\n",
      "[Epoch 3/50] Step 100/938 Loss_D: -1.4407 Loss_G: -8.6987\n",
      "[Epoch 3/50] Step 200/938 Loss_D: -2.0232 Loss_G: 7.5596\n",
      "[Epoch 3/50] Step 300/938 Loss_D: -1.7194 Loss_G: 3.8948\n",
      "[Epoch 3/50] Step 400/938 Loss_D: -1.0609 Loss_G: -3.2198\n",
      "[Epoch 3/50] Step 500/938 Loss_D: -1.6147 Loss_G: -1.8447\n",
      "[Epoch 3/50] Step 600/938 Loss_D: -1.3555 Loss_G: -2.1983\n",
      "[Epoch 3/50] Step 700/938 Loss_D: -1.4482 Loss_G: -0.8233\n",
      "[Epoch 3/50] Step 800/938 Loss_D: -1.3643 Loss_G: -4.0767\n",
      "[Epoch 3/50] Step 900/938 Loss_D: -1.7112 Loss_G: 6.1184\n",
      "[Epoch 4/50] Step 0/938 Loss_D: -1.2262 Loss_G: 3.9311\n",
      "[Epoch 4/50] Step 100/938 Loss_D: -1.1549 Loss_G: -0.4464\n",
      "[Epoch 4/50] Step 200/938 Loss_D: -0.8423 Loss_G: -8.7875\n",
      "[Epoch 4/50] Step 300/938 Loss_D: -1.4879 Loss_G: 4.9359\n",
      "[Epoch 4/50] Step 400/938 Loss_D: -1.1917 Loss_G: -4.2489\n",
      "[Epoch 4/50] Step 500/938 Loss_D: -0.9507 Loss_G: -2.6902\n",
      "[Epoch 4/50] Step 600/938 Loss_D: -1.2016 Loss_G: -2.1493\n",
      "[Epoch 4/50] Step 700/938 Loss_D: -1.2519 Loss_G: -3.4969\n",
      "[Epoch 4/50] Step 800/938 Loss_D: -1.1553 Loss_G: -8.4430\n",
      "[Epoch 4/50] Step 900/938 Loss_D: -1.4462 Loss_G: 2.2131\n",
      "[Epoch 5/50] Step 0/938 Loss_D: -0.9299 Loss_G: 5.3843\n",
      "[Epoch 5/50] Step 100/938 Loss_D: -1.0008 Loss_G: -5.3465\n",
      "[Epoch 5/50] Step 200/938 Loss_D: -1.1022 Loss_G: -7.3694\n",
      "[Epoch 5/50] Step 300/938 Loss_D: -0.9226 Loss_G: -4.8124\n",
      "[Epoch 5/50] Step 400/938 Loss_D: -1.1443 Loss_G: -3.0382\n",
      "[Epoch 5/50] Step 500/938 Loss_D: -1.0822 Loss_G: -6.6273\n",
      "[Epoch 5/50] Step 600/938 Loss_D: -1.4517 Loss_G: -7.3164\n",
      "[Epoch 5/50] Step 700/938 Loss_D: -0.5982 Loss_G: -5.2054\n",
      "[Epoch 5/50] Step 800/938 Loss_D: -1.0586 Loss_G: -2.5054\n",
      "[Epoch 5/50] Step 900/938 Loss_D: -1.1328 Loss_G: -2.1985\n",
      "[Epoch 6/50] Step 0/938 Loss_D: -1.1680 Loss_G: -8.0130\n",
      "[Epoch 6/50] Step 100/938 Loss_D: -0.8050 Loss_G: -0.6457\n",
      "[Epoch 6/50] Step 200/938 Loss_D: -0.6867 Loss_G: 3.1285\n",
      "[Epoch 6/50] Step 300/938 Loss_D: -1.0020 Loss_G: -6.7173\n",
      "[Epoch 6/50] Step 400/938 Loss_D: -0.6867 Loss_G: -6.2293\n",
      "[Epoch 6/50] Step 500/938 Loss_D: -1.0598 Loss_G: -5.3315\n",
      "[Epoch 6/50] Step 600/938 Loss_D: -0.7577 Loss_G: -3.4583\n",
      "[Epoch 6/50] Step 700/938 Loss_D: -0.9570 Loss_G: -6.1233\n",
      "[Epoch 6/50] Step 800/938 Loss_D: -1.1757 Loss_G: -3.7911\n",
      "[Epoch 6/50] Step 900/938 Loss_D: -0.9749 Loss_G: -4.7524\n",
      "[Epoch 7/50] Step 0/938 Loss_D: -0.8955 Loss_G: -9.1385\n",
      "[Epoch 7/50] Step 100/938 Loss_D: -1.1461 Loss_G: 5.2076\n",
      "[Epoch 7/50] Step 200/938 Loss_D: -0.8863 Loss_G: 6.5721\n",
      "[Epoch 7/50] Step 300/938 Loss_D: -1.3024 Loss_G: -8.8159\n",
      "[Epoch 7/50] Step 400/938 Loss_D: -0.6471 Loss_G: -6.1178\n",
      "[Epoch 7/50] Step 500/938 Loss_D: -1.1240 Loss_G: -1.4387\n",
      "[Epoch 7/50] Step 600/938 Loss_D: -1.0813 Loss_G: -6.8154\n",
      "[Epoch 7/50] Step 700/938 Loss_D: -0.6890 Loss_G: -7.8602\n",
      "[Epoch 7/50] Step 800/938 Loss_D: -0.9653 Loss_G: -8.6528\n",
      "[Epoch 7/50] Step 900/938 Loss_D: -1.0897 Loss_G: -7.1143\n",
      "[Epoch 8/50] Step 0/938 Loss_D: -0.7153 Loss_G: -8.2441\n",
      "[Epoch 8/50] Step 100/938 Loss_D: -0.7602 Loss_G: -6.8587\n",
      "[Epoch 8/50] Step 200/938 Loss_D: -0.5976 Loss_G: -1.5335\n",
      "[Epoch 8/50] Step 300/938 Loss_D: -1.0471 Loss_G: -9.2154\n",
      "[Epoch 8/50] Step 400/938 Loss_D: -0.8257 Loss_G: 2.1697\n",
      "[Epoch 8/50] Step 500/938 Loss_D: -0.7721 Loss_G: -6.6759\n",
      "[Epoch 8/50] Step 600/938 Loss_D: -1.5299 Loss_G: 7.8477\n",
      "[Epoch 8/50] Step 700/938 Loss_D: -0.5467 Loss_G: -8.8864\n",
      "[Epoch 8/50] Step 800/938 Loss_D: -0.4896 Loss_G: -9.6052\n",
      "[Epoch 8/50] Step 900/938 Loss_D: -0.8710 Loss_G: -3.9435\n",
      "[Epoch 9/50] Step 0/938 Loss_D: -0.8996 Loss_G: -7.3005\n",
      "[Epoch 9/50] Step 100/938 Loss_D: -0.8367 Loss_G: -8.1409\n",
      "[Epoch 9/50] Step 200/938 Loss_D: -0.5196 Loss_G: -2.6915\n",
      "[Epoch 9/50] Step 300/938 Loss_D: -0.6620 Loss_G: -10.4547\n",
      "[Epoch 9/50] Step 400/938 Loss_D: -0.9257 Loss_G: -2.4111\n",
      "[Epoch 9/50] Step 500/938 Loss_D: -0.8563 Loss_G: 5.2636\n",
      "[Epoch 9/50] Step 600/938 Loss_D: -0.8757 Loss_G: 5.6820\n",
      "[Epoch 9/50] Step 700/938 Loss_D: -0.7311 Loss_G: -4.4094\n",
      "[Epoch 9/50] Step 800/938 Loss_D: -0.8661 Loss_G: -1.5084\n",
      "[Epoch 9/50] Step 900/938 Loss_D: -0.6626 Loss_G: -6.3246\n",
      "[Epoch 10/50] Step 0/938 Loss_D: -0.8503 Loss_G: -9.8977\n",
      "[Epoch 10/50] Step 100/938 Loss_D: -0.8597 Loss_G: -7.5684\n",
      "[Epoch 10/50] Step 200/938 Loss_D: -0.6154 Loss_G: -5.2464\n",
      "[Epoch 10/50] Step 300/938 Loss_D: -0.4887 Loss_G: -6.2550\n",
      "[Epoch 10/50] Step 400/938 Loss_D: -0.8454 Loss_G: -9.2495\n",
      "[Epoch 10/50] Step 500/938 Loss_D: -0.4285 Loss_G: -5.1681\n",
      "[Epoch 10/50] Step 600/938 Loss_D: -1.0249 Loss_G: 3.4679\n",
      "[Epoch 10/50] Step 700/938 Loss_D: -0.7186 Loss_G: -2.9412\n",
      "[Epoch 10/50] Step 800/938 Loss_D: -0.5032 Loss_G: 1.2897\n",
      "[Epoch 10/50] Step 900/938 Loss_D: -0.5049 Loss_G: 0.7604\n",
      "[Epoch 11/50] Step 0/938 Loss_D: -0.8258 Loss_G: -1.8776\n",
      "[Epoch 11/50] Step 100/938 Loss_D: -0.4442 Loss_G: 1.9545\n",
      "[Epoch 11/50] Step 200/938 Loss_D: -0.7019 Loss_G: -2.9014\n",
      "[Epoch 11/50] Step 300/938 Loss_D: -0.9121 Loss_G: -9.8197\n",
      "[Epoch 11/50] Step 400/938 Loss_D: -0.8323 Loss_G: -1.1957\n",
      "[Epoch 11/50] Step 500/938 Loss_D: -0.7702 Loss_G: -9.1305\n",
      "[Epoch 11/50] Step 600/938 Loss_D: -0.4258 Loss_G: -1.1791\n",
      "[Epoch 11/50] Step 700/938 Loss_D: -0.4838 Loss_G: 2.6781\n",
      "[Epoch 11/50] Step 800/938 Loss_D: -1.0242 Loss_G: 7.2985\n",
      "[Epoch 11/50] Step 900/938 Loss_D: -0.4311 Loss_G: -4.6177\n",
      "[Epoch 12/50] Step 0/938 Loss_D: -0.5974 Loss_G: -1.3949\n",
      "[Epoch 12/50] Step 100/938 Loss_D: -1.0283 Loss_G: -10.0268\n",
      "[Epoch 12/50] Step 200/938 Loss_D: -0.8859 Loss_G: -9.8308\n",
      "[Epoch 12/50] Step 300/938 Loss_D: -0.7798 Loss_G: 2.3671\n",
      "[Epoch 12/50] Step 400/938 Loss_D: -0.4634 Loss_G: 7.7210\n",
      "[Epoch 12/50] Step 500/938 Loss_D: -0.8455 Loss_G: -5.3894\n",
      "[Epoch 12/50] Step 600/938 Loss_D: -0.6733 Loss_G: -2.7174\n",
      "[Epoch 12/50] Step 700/938 Loss_D: -0.7733 Loss_G: -10.8349\n",
      "[Epoch 12/50] Step 800/938 Loss_D: -0.6933 Loss_G: -6.5298\n",
      "[Epoch 12/50] Step 900/938 Loss_D: -0.7903 Loss_G: -15.3524\n",
      "[Epoch 13/50] Step 0/938 Loss_D: -1.0194 Loss_G: -9.7956\n",
      "[Epoch 13/50] Step 100/938 Loss_D: -0.8292 Loss_G: -9.6363\n",
      "[Epoch 13/50] Step 200/938 Loss_D: -0.7398 Loss_G: -2.7670\n",
      "[Epoch 13/50] Step 300/938 Loss_D: -1.0137 Loss_G: 7.1914\n",
      "[Epoch 13/50] Step 400/938 Loss_D: -0.6524 Loss_G: 2.5019\n",
      "[Epoch 13/50] Step 500/938 Loss_D: -1.1722 Loss_G: -10.6710\n",
      "[Epoch 13/50] Step 600/938 Loss_D: -0.6256 Loss_G: -8.0731\n",
      "[Epoch 13/50] Step 700/938 Loss_D: -0.5960 Loss_G: 2.6767\n",
      "[Epoch 13/50] Step 800/938 Loss_D: -0.6059 Loss_G: -5.0245\n",
      "[Epoch 13/50] Step 900/938 Loss_D: -0.4937 Loss_G: -4.0031\n",
      "[Epoch 14/50] Step 0/938 Loss_D: -0.4076 Loss_G: -4.2080\n",
      "[Epoch 14/50] Step 100/938 Loss_D: -0.3552 Loss_G: 2.0524\n",
      "[Epoch 14/50] Step 200/938 Loss_D: -0.6513 Loss_G: -3.4840\n",
      "[Epoch 14/50] Step 300/938 Loss_D: -0.5854 Loss_G: -5.4966\n",
      "[Epoch 14/50] Step 400/938 Loss_D: -0.6469 Loss_G: -9.1256\n",
      "[Epoch 14/50] Step 500/938 Loss_D: -0.5798 Loss_G: -6.9595\n",
      "[Epoch 14/50] Step 600/938 Loss_D: -0.9816 Loss_G: -11.6909\n",
      "[Epoch 14/50] Step 700/938 Loss_D: -0.7876 Loss_G: -1.8779\n",
      "[Epoch 14/50] Step 800/938 Loss_D: -0.5592 Loss_G: 0.8531\n",
      "[Epoch 14/50] Step 900/938 Loss_D: -0.8237 Loss_G: 8.5357\n",
      "[Epoch 15/50] Step 0/938 Loss_D: -0.5448 Loss_G: -10.0650\n",
      "[Epoch 15/50] Step 100/938 Loss_D: -0.7278 Loss_G: 5.6757\n",
      "[Epoch 15/50] Step 200/938 Loss_D: -0.5962 Loss_G: 4.5262\n",
      "[Epoch 15/50] Step 300/938 Loss_D: -0.4135 Loss_G: 1.1443\n",
      "[Epoch 15/50] Step 400/938 Loss_D: -0.4579 Loss_G: -3.5419\n",
      "[Epoch 15/50] Step 500/938 Loss_D: -0.5190 Loss_G: -7.8827\n",
      "[Epoch 15/50] Step 600/938 Loss_D: -0.5898 Loss_G: -1.7500\n",
      "[Epoch 15/50] Step 700/938 Loss_D: -0.3406 Loss_G: -5.1351\n",
      "[Epoch 15/50] Step 800/938 Loss_D: -0.0993 Loss_G: -9.2612\n",
      "[Epoch 15/50] Step 900/938 Loss_D: -0.7549 Loss_G: -10.0920\n",
      "[Epoch 16/50] Step 0/938 Loss_D: -2.1733 Loss_G: -11.3003\n",
      "[Epoch 16/50] Step 100/938 Loss_D: -0.7766 Loss_G: -3.0259\n",
      "[Epoch 16/50] Step 200/938 Loss_D: -0.6055 Loss_G: -9.5280\n",
      "[Epoch 16/50] Step 300/938 Loss_D: -0.8882 Loss_G: -9.0515\n",
      "[Epoch 16/50] Step 400/938 Loss_D: -0.8504 Loss_G: -12.9451\n",
      "[Epoch 16/50] Step 500/938 Loss_D: -0.4504 Loss_G: 5.2658\n",
      "[Epoch 16/50] Step 600/938 Loss_D: -0.8259 Loss_G: -3.1646\n",
      "[Epoch 16/50] Step 700/938 Loss_D: -0.3499 Loss_G: 6.6225\n",
      "[Epoch 16/50] Step 800/938 Loss_D: -0.2596 Loss_G: -1.3917\n",
      "[Epoch 16/50] Step 900/938 Loss_D: -0.3805 Loss_G: -7.4198\n",
      "[Epoch 17/50] Step 0/938 Loss_D: -0.4766 Loss_G: 0.9919\n",
      "[Epoch 17/50] Step 100/938 Loss_D: -1.3519 Loss_G: 7.5070\n",
      "[Epoch 17/50] Step 200/938 Loss_D: -0.2089 Loss_G: -16.1957\n",
      "[Epoch 17/50] Step 300/938 Loss_D: -0.5775 Loss_G: 4.7080\n",
      "[Epoch 17/50] Step 400/938 Loss_D: -1.4523 Loss_G: 8.7347\n",
      "[Epoch 17/50] Step 500/938 Loss_D: -0.3638 Loss_G: 3.5711\n",
      "[Epoch 17/50] Step 600/938 Loss_D: -0.8259 Loss_G: 3.6480\n",
      "[Epoch 17/50] Step 700/938 Loss_D: -0.1347 Loss_G: -2.0039\n",
      "[Epoch 17/50] Step 800/938 Loss_D: -0.5981 Loss_G: -12.2910\n",
      "[Epoch 17/50] Step 900/938 Loss_D: -0.2243 Loss_G: -12.5967\n",
      "[Epoch 18/50] Step 0/938 Loss_D: -0.6326 Loss_G: -9.0381\n",
      "[Epoch 18/50] Step 100/938 Loss_D: -0.3512 Loss_G: -12.6695\n",
      "[Epoch 18/50] Step 200/938 Loss_D: -0.1650 Loss_G: -10.7831\n",
      "[Epoch 18/50] Step 300/938 Loss_D: -0.3658 Loss_G: -9.8949\n",
      "[Epoch 18/50] Step 400/938 Loss_D: -0.4265 Loss_G: -9.7965\n",
      "[Epoch 18/50] Step 500/938 Loss_D: -0.9683 Loss_G: 9.8419\n",
      "[Epoch 18/50] Step 600/938 Loss_D: -0.6756 Loss_G: -8.7371\n",
      "[Epoch 18/50] Step 700/938 Loss_D: -0.4488 Loss_G: -5.4297\n",
      "[Epoch 18/50] Step 800/938 Loss_D: -0.3166 Loss_G: -1.4502\n",
      "[Epoch 18/50] Step 900/938 Loss_D: -0.9695 Loss_G: -11.7636\n",
      "[Epoch 19/50] Step 0/938 Loss_D: -0.6203 Loss_G: -7.4479\n",
      "[Epoch 19/50] Step 100/938 Loss_D: -0.3019 Loss_G: -6.3408\n",
      "[Epoch 19/50] Step 200/938 Loss_D: -1.0209 Loss_G: 6.6155\n",
      "[Epoch 19/50] Step 300/938 Loss_D: -0.7565 Loss_G: 0.9182\n",
      "[Epoch 19/50] Step 400/938 Loss_D: -0.3566 Loss_G: -12.6553\n",
      "[Epoch 19/50] Step 500/938 Loss_D: -0.8457 Loss_G: 9.0447\n",
      "[Epoch 19/50] Step 600/938 Loss_D: -0.3481 Loss_G: 4.1474\n",
      "[Epoch 19/50] Step 700/938 Loss_D: -0.6258 Loss_G: 7.8740\n",
      "[Epoch 19/50] Step 800/938 Loss_D: -0.4358 Loss_G: 2.2195\n",
      "[Epoch 19/50] Step 900/938 Loss_D: -0.5085 Loss_G: 7.5679\n",
      "[Epoch 20/50] Step 0/938 Loss_D: -0.8138 Loss_G: 9.7738\n",
      "[Epoch 20/50] Step 100/938 Loss_D: -0.3953 Loss_G: 0.4307\n",
      "[Epoch 20/50] Step 200/938 Loss_D: -0.3058 Loss_G: 8.9130\n",
      "[Epoch 20/50] Step 300/938 Loss_D: -0.6924 Loss_G: -11.1522\n",
      "[Epoch 20/50] Step 400/938 Loss_D: -0.9880 Loss_G: 11.8432\n",
      "[Epoch 20/50] Step 500/938 Loss_D: -0.5377 Loss_G: -17.5292\n",
      "[Epoch 20/50] Step 600/938 Loss_D: -0.2554 Loss_G: -9.0537\n",
      "[Epoch 20/50] Step 700/938 Loss_D: -0.4910 Loss_G: -5.4347\n",
      "[Epoch 20/50] Step 800/938 Loss_D: -0.5623 Loss_G: 0.0040\n",
      "[Epoch 20/50] Step 900/938 Loss_D: -0.5253 Loss_G: 2.3791\n",
      "[Epoch 21/50] Step 0/938 Loss_D: -1.0691 Loss_G: -16.9902\n",
      "[Epoch 21/50] Step 100/938 Loss_D: -0.3415 Loss_G: 1.6074\n",
      "[Epoch 21/50] Step 200/938 Loss_D: -0.5414 Loss_G: 6.8177\n",
      "[Epoch 21/50] Step 300/938 Loss_D: -0.5283 Loss_G: 6.1326\n",
      "[Epoch 21/50] Step 400/938 Loss_D: -0.3342 Loss_G: 2.7716\n",
      "[Epoch 21/50] Step 500/938 Loss_D: -0.3875 Loss_G: -3.2192\n",
      "[Epoch 21/50] Step 600/938 Loss_D: -1.0460 Loss_G: 8.6230\n",
      "[Epoch 21/50] Step 700/938 Loss_D: -0.0606 Loss_G: 0.3898\n",
      "[Epoch 21/50] Step 800/938 Loss_D: -0.4354 Loss_G: 6.0058\n",
      "[Epoch 21/50] Step 900/938 Loss_D: -1.0187 Loss_G: -17.4230\n",
      "[Epoch 22/50] Step 0/938 Loss_D: -0.5752 Loss_G: 10.0958\n",
      "[Epoch 22/50] Step 100/938 Loss_D: -0.1397 Loss_G: 4.6372\n",
      "[Epoch 22/50] Step 200/938 Loss_D: -0.5839 Loss_G: 2.6534\n",
      "[Epoch 22/50] Step 300/938 Loss_D: -0.4603 Loss_G: -5.8593\n",
      "[Epoch 22/50] Step 400/938 Loss_D: -0.3565 Loss_G: 1.1821\n",
      "[Epoch 22/50] Step 500/938 Loss_D: -0.4712 Loss_G: -0.9971\n",
      "[Epoch 22/50] Step 600/938 Loss_D: -0.3374 Loss_G: -3.3210\n",
      "[Epoch 22/50] Step 700/938 Loss_D: -0.2871 Loss_G: 3.5695\n",
      "[Epoch 22/50] Step 800/938 Loss_D: -0.8143 Loss_G: 5.8783\n",
      "[Epoch 22/50] Step 900/938 Loss_D: -0.2926 Loss_G: -0.4481\n",
      "[Epoch 23/50] Step 0/938 Loss_D: -0.6038 Loss_G: 5.5869\n",
      "[Epoch 23/50] Step 100/938 Loss_D: -0.6189 Loss_G: -12.7951\n",
      "[Epoch 23/50] Step 200/938 Loss_D: 0.1192 Loss_G: -18.4915\n",
      "[Epoch 23/50] Step 300/938 Loss_D: -0.4197 Loss_G: 9.1904\n",
      "[Epoch 23/50] Step 400/938 Loss_D: -0.3965 Loss_G: -3.5987\n",
      "[Epoch 23/50] Step 500/938 Loss_D: -0.6403 Loss_G: -14.3172\n",
      "[Epoch 23/50] Step 600/938 Loss_D: -0.2183 Loss_G: -6.4722\n",
      "[Epoch 23/50] Step 700/938 Loss_D: -0.2806 Loss_G: -5.2031\n",
      "[Epoch 23/50] Step 800/938 Loss_D: -0.4016 Loss_G: -7.2772\n",
      "[Epoch 23/50] Step 900/938 Loss_D: -0.1621 Loss_G: 10.9752\n",
      "[Epoch 24/50] Step 0/938 Loss_D: -0.3278 Loss_G: -17.8635\n",
      "[Epoch 24/50] Step 100/938 Loss_D: -0.3190 Loss_G: -6.9613\n",
      "[Epoch 24/50] Step 200/938 Loss_D: -0.0785 Loss_G: -6.0240\n",
      "[Epoch 24/50] Step 300/938 Loss_D: -0.1568 Loss_G: 0.7180\n",
      "[Epoch 24/50] Step 400/938 Loss_D: -0.3231 Loss_G: -12.4728\n",
      "[Epoch 24/50] Step 500/938 Loss_D: -0.3963 Loss_G: -5.5829\n",
      "[Epoch 24/50] Step 600/938 Loss_D: -0.6402 Loss_G: -8.0605\n",
      "[Epoch 24/50] Step 700/938 Loss_D: 0.2630 Loss_G: -13.8132\n",
      "[Epoch 24/50] Step 800/938 Loss_D: -0.2977 Loss_G: -3.7329\n",
      "[Epoch 24/50] Step 900/938 Loss_D: -0.2532 Loss_G: 4.2294\n",
      "[Epoch 25/50] Step 0/938 Loss_D: -0.3335 Loss_G: -1.4501\n",
      "[Epoch 25/50] Step 100/938 Loss_D: -0.4739 Loss_G: -4.0123\n",
      "[Epoch 25/50] Step 200/938 Loss_D: -0.4211 Loss_G: -11.4170\n",
      "[Epoch 25/50] Step 300/938 Loss_D: -0.5260 Loss_G: 2.8402\n",
      "[Epoch 25/50] Step 400/938 Loss_D: -0.3230 Loss_G: -5.0467\n",
      "[Epoch 25/50] Step 500/938 Loss_D: -0.3374 Loss_G: -3.8358\n",
      "[Epoch 25/50] Step 600/938 Loss_D: -0.9551 Loss_G: 7.0926\n",
      "[Epoch 25/50] Step 700/938 Loss_D: -0.7134 Loss_G: -15.4604\n",
      "[Epoch 25/50] Step 800/938 Loss_D: -0.7451 Loss_G: -13.4784\n",
      "[Epoch 25/50] Step 900/938 Loss_D: -0.6133 Loss_G: -5.8399\n",
      "[Epoch 26/50] Step 0/938 Loss_D: -0.1441 Loss_G: -2.1918\n",
      "[Epoch 26/50] Step 100/938 Loss_D: -1.2600 Loss_G: -17.4256\n",
      "[Epoch 26/50] Step 200/938 Loss_D: -0.1594 Loss_G: 12.8866\n",
      "[Epoch 26/50] Step 300/938 Loss_D: 0.2265 Loss_G: -13.0859\n",
      "[Epoch 26/50] Step 400/938 Loss_D: 0.1426 Loss_G: -4.6278\n",
      "[Epoch 26/50] Step 500/938 Loss_D: 0.2089 Loss_G: -2.9137\n",
      "[Epoch 26/50] Step 600/938 Loss_D: -1.3848 Loss_G: 6.5058\n",
      "[Epoch 26/50] Step 700/938 Loss_D: -0.5938 Loss_G: -3.2315\n",
      "[Epoch 26/50] Step 800/938 Loss_D: -0.8707 Loss_G: -3.8154\n",
      "[Epoch 26/50] Step 900/938 Loss_D: -0.4298 Loss_G: -3.6943\n",
      "[Epoch 27/50] Step 0/938 Loss_D: -0.1490 Loss_G: -7.0043\n",
      "[Epoch 27/50] Step 100/938 Loss_D: -0.9764 Loss_G: -0.9218\n",
      "[Epoch 27/50] Step 200/938 Loss_D: -0.7359 Loss_G: -3.0124\n",
      "[Epoch 27/50] Step 300/938 Loss_D: -0.6420 Loss_G: -2.7645\n",
      "[Epoch 27/50] Step 400/938 Loss_D: -0.7231 Loss_G: -0.1417\n",
      "[Epoch 27/50] Step 500/938 Loss_D: -0.5200 Loss_G: -6.1921\n",
      "[Epoch 27/50] Step 600/938 Loss_D: -0.9453 Loss_G: -3.5946\n",
      "[Epoch 27/50] Step 700/938 Loss_D: -1.2403 Loss_G: -6.4153\n",
      "[Epoch 27/50] Step 800/938 Loss_D: -0.6218 Loss_G: -3.5038\n",
      "[Epoch 27/50] Step 900/938 Loss_D: -0.8336 Loss_G: -1.7687\n",
      "[Epoch 28/50] Step 0/938 Loss_D: -0.4586 Loss_G: -2.1717\n",
      "[Epoch 28/50] Step 100/938 Loss_D: -0.6805 Loss_G: -3.1769\n",
      "[Epoch 28/50] Step 200/938 Loss_D: -0.7409 Loss_G: -5.0986\n",
      "[Epoch 28/50] Step 300/938 Loss_D: -0.6200 Loss_G: -7.0647\n",
      "[Epoch 28/50] Step 400/938 Loss_D: -0.7287 Loss_G: -5.2103\n",
      "[Epoch 28/50] Step 500/938 Loss_D: -0.5151 Loss_G: -6.4839\n",
      "[Epoch 28/50] Step 600/938 Loss_D: -0.4810 Loss_G: -2.7016\n",
      "[Epoch 28/50] Step 700/938 Loss_D: -0.9678 Loss_G: -4.2383\n",
      "[Epoch 28/50] Step 800/938 Loss_D: -0.4306 Loss_G: -3.2405\n",
      "[Epoch 28/50] Step 900/938 Loss_D: -0.7233 Loss_G: -2.8783\n",
      "[Epoch 29/50] Step 0/938 Loss_D: -0.7378 Loss_G: 0.4089\n",
      "[Epoch 29/50] Step 100/938 Loss_D: -0.8814 Loss_G: -1.0847\n",
      "[Epoch 29/50] Step 200/938 Loss_D: -0.7950 Loss_G: -1.5814\n",
      "[Epoch 29/50] Step 300/938 Loss_D: -0.7680 Loss_G: -5.2079\n",
      "[Epoch 29/50] Step 400/938 Loss_D: -0.5500 Loss_G: -3.3472\n",
      "[Epoch 29/50] Step 500/938 Loss_D: -0.6840 Loss_G: -4.8063\n",
      "[Epoch 29/50] Step 600/938 Loss_D: -2.1148 Loss_G: 1.1156\n",
      "[Epoch 29/50] Step 700/938 Loss_D: -0.8964 Loss_G: -5.2563\n",
      "[Epoch 29/50] Step 800/938 Loss_D: -0.9286 Loss_G: -3.0372\n",
      "[Epoch 29/50] Step 900/938 Loss_D: -1.1309 Loss_G: -4.1395\n",
      "[Epoch 30/50] Step 0/938 Loss_D: -0.9311 Loss_G: -4.4689\n",
      "[Epoch 30/50] Step 100/938 Loss_D: -1.2303 Loss_G: -4.2451\n",
      "[Epoch 30/50] Step 200/938 Loss_D: -0.5971 Loss_G: -5.0447\n",
      "[Epoch 30/50] Step 300/938 Loss_D: -0.7707 Loss_G: -1.4280\n",
      "[Epoch 30/50] Step 400/938 Loss_D: -0.8260 Loss_G: -1.4940\n",
      "[Epoch 30/50] Step 500/938 Loss_D: -1.2306 Loss_G: -2.2383\n",
      "[Epoch 30/50] Step 600/938 Loss_D: -1.7248 Loss_G: -4.3995\n",
      "[Epoch 30/50] Step 700/938 Loss_D: -0.6318 Loss_G: -4.4886\n",
      "[Epoch 30/50] Step 800/938 Loss_D: -0.9393 Loss_G: -2.2329\n",
      "[Epoch 30/50] Step 900/938 Loss_D: -0.4632 Loss_G: 0.9841\n",
      "[Epoch 31/50] Step 0/938 Loss_D: -0.8160 Loss_G: 0.3217\n",
      "[Epoch 31/50] Step 100/938 Loss_D: -0.5454 Loss_G: -3.5158\n",
      "[Epoch 31/50] Step 200/938 Loss_D: -0.7941 Loss_G: -4.9234\n",
      "[Epoch 31/50] Step 300/938 Loss_D: -0.7081 Loss_G: -0.5705\n",
      "[Epoch 31/50] Step 400/938 Loss_D: -0.5485 Loss_G: 0.5656\n",
      "[Epoch 31/50] Step 500/938 Loss_D: -0.9852 Loss_G: -4.9036\n",
      "[Epoch 31/50] Step 600/938 Loss_D: -0.6414 Loss_G: -3.7813\n",
      "[Epoch 31/50] Step 700/938 Loss_D: -0.7946 Loss_G: -6.3494\n",
      "[Epoch 31/50] Step 800/938 Loss_D: -0.9835 Loss_G: -5.2318\n",
      "[Epoch 31/50] Step 900/938 Loss_D: -0.6855 Loss_G: -3.1539\n",
      "[Epoch 32/50] Step 0/938 Loss_D: -0.9906 Loss_G: -3.1530\n",
      "[Epoch 32/50] Step 100/938 Loss_D: -0.6206 Loss_G: -2.8036\n",
      "[Epoch 32/50] Step 200/938 Loss_D: -0.9774 Loss_G: -1.9456\n",
      "[Epoch 32/50] Step 300/938 Loss_D: -1.4079 Loss_G: -3.8487\n",
      "[Epoch 32/50] Step 400/938 Loss_D: -0.5368 Loss_G: -1.8174\n",
      "[Epoch 32/50] Step 500/938 Loss_D: -1.1188 Loss_G: -0.5492\n",
      "[Epoch 32/50] Step 600/938 Loss_D: -1.2523 Loss_G: -3.2723\n",
      "[Epoch 32/50] Step 700/938 Loss_D: -1.0224 Loss_G: 0.0905\n",
      "[Epoch 32/50] Step 800/938 Loss_D: -0.9782 Loss_G: -1.5106\n",
      "[Epoch 32/50] Step 900/938 Loss_D: -0.7249 Loss_G: 1.2185\n",
      "[Epoch 33/50] Step 0/938 Loss_D: -0.7027 Loss_G: 3.5727\n",
      "[Epoch 33/50] Step 100/938 Loss_D: -0.9965 Loss_G: -3.9942\n",
      "[Epoch 33/50] Step 200/938 Loss_D: -0.7388 Loss_G: -1.1392\n",
      "[Epoch 33/50] Step 300/938 Loss_D: -1.0143 Loss_G: -2.0567\n",
      "[Epoch 33/50] Step 400/938 Loss_D: -0.9869 Loss_G: 0.3111\n",
      "[Epoch 33/50] Step 500/938 Loss_D: -0.7359 Loss_G: -4.7609\n",
      "[Epoch 33/50] Step 600/938 Loss_D: -0.2341 Loss_G: -2.1788\n",
      "[Epoch 33/50] Step 700/938 Loss_D: -1.1138 Loss_G: 2.6737\n",
      "[Epoch 33/50] Step 800/938 Loss_D: -0.4823 Loss_G: -2.5907\n",
      "[Epoch 33/50] Step 900/938 Loss_D: -0.7582 Loss_G: -4.9322\n",
      "[Epoch 34/50] Step 0/938 Loss_D: -1.0106 Loss_G: -3.9756\n",
      "[Epoch 34/50] Step 100/938 Loss_D: -0.9148 Loss_G: -3.1208\n",
      "[Epoch 34/50] Step 200/938 Loss_D: -0.7330 Loss_G: 3.3097\n",
      "[Epoch 34/50] Step 300/938 Loss_D: -0.8095 Loss_G: -2.6558\n",
      "[Epoch 34/50] Step 400/938 Loss_D: -0.8619 Loss_G: 5.4823\n",
      "[Epoch 34/50] Step 500/938 Loss_D: -0.6205 Loss_G: -2.2859\n",
      "[Epoch 34/50] Step 600/938 Loss_D: -0.7942 Loss_G: -2.0871\n",
      "[Epoch 34/50] Step 700/938 Loss_D: -0.3477 Loss_G: -0.1318\n",
      "[Epoch 34/50] Step 800/938 Loss_D: -0.4771 Loss_G: 0.5462\n",
      "[Epoch 34/50] Step 900/938 Loss_D: -1.0431 Loss_G: -0.6524\n",
      "[Epoch 35/50] Step 0/938 Loss_D: -0.4130 Loss_G: 2.9302\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Create folder for generated images\n",
    "os.makedirs(\"generated_images\", exist_ok=True)\n",
    "\n",
    "# Transform to normalize the data between -1 and 1\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=64, shuffle=True, num_workers=2\n",
    ")\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Generator\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, latent_dim=100):\n",
    "        super(Generator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 256),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(256, 512),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(512, 1024),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(1024, 28*28),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        output = self.main(input)\n",
    "        return output.view(-1, 1, 28, 28)\n",
    "\n",
    "# Discriminator (WGAN Critic)\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.main = nn.Sequential(\n",
    "            nn.Linear(28*28, 1024),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.LeakyReLU(0.2, inplace=True),\n",
    "            nn.Linear(256, 1)\n",
    "        )\n",
    "\n",
    "    def forward(self, input):\n",
    "        input = input.view(-1, 28*28)\n",
    "        return self.main(input)\n",
    "\n",
    "# Weight initialization\n",
    "def weights_init(m):\n",
    "    classname = m.__class__.__name__\n",
    "    if classname.find('Linear') != -1:\n",
    "        nn.init.kaiming_uniform_(m.weight.data, a=0.2)\n",
    "        if m.bias is not None:\n",
    "            m.bias.data.fill_(0)\n",
    "\n",
    "# Initialize models\n",
    "latent_dim = 100\n",
    "generator = Generator(latent_dim).to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "generator.apply(weights_init)\n",
    "discriminator.apply(weights_init)\n",
    "\n",
    "# Optimizers\n",
    "optimizer_G = optim.RMSprop(generator.parameters(), lr=0.00005)\n",
    "optimizer_D = optim.RMSprop(discriminator.parameters(), lr=0.00005)\n",
    "\n",
    "# WGAN parameters\n",
    "n_critic = 5\n",
    "clip_value = 0.01\n",
    "num_epochs = 50\n",
    "fixed_noise = torch.randn(64, latent_dim, device=device)\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "img_list = []\n",
    "\n",
    "print(\"Starting Training Loop...\")\n",
    "for epoch in range(num_epochs):\n",
    "    for i, data in enumerate(trainloader):\n",
    "        real_images = data[0].to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "\n",
    "        # ---------------------\n",
    "        # Train Discriminator\n",
    "        # ---------------------\n",
    "        for _ in range(n_critic):\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            real_output = discriminator(real_images).view(-1)\n",
    "            noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "            fake_images = generator(noise)\n",
    "            fake_output = discriminator(fake_images.detach()).view(-1)\n",
    "\n",
    "            d_loss = -(torch.mean(real_output) - torch.mean(fake_output))\n",
    "            d_loss.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Clip weights\n",
    "            for p in discriminator.parameters():\n",
    "                p.data.clamp_(-clip_value, clip_value)\n",
    "\n",
    "        # -----------------\n",
    "        # Train Generator\n",
    "        # -----------------\n",
    "        optimizer_G.zero_grad()\n",
    "        noise = torch.randn(batch_size, latent_dim, device=device)\n",
    "        fake_images = generator(noise)\n",
    "        fake_output = discriminator(fake_images).view(-1)\n",
    "        g_loss = -torch.mean(fake_output)\n",
    "        g_loss.backward()\n",
    "        optimizer_G.step()\n",
    "\n",
    "        # Save losses\n",
    "        G_losses.append(g_loss.item())\n",
    "        D_losses.append(d_loss.item())\n",
    "\n",
    "        if i % 100 == 0:\n",
    "            print(f\"[Epoch {epoch}/{num_epochs}] Step {i}/{len(trainloader)} \"\n",
    "                  f\"Loss_D: {d_loss.item():.4f} Loss_G: {g_loss.item():.4f}\")\n",
    "\n",
    "    # Save generated images for the current epoch\n",
    "    with torch.no_grad():\n",
    "        fake = generator(fixed_noise).detach().cpu()\n",
    "    grid = torchvision.utils.make_grid(fake, padding=2, normalize=True)\n",
    "    img_list.append(grid)\n",
    "\n",
    "    plt.figure(figsize=(6, 6))\n",
    "    plt.axis(\"off\")\n",
    "    plt.title(f\"Epoch {epoch}\")\n",
    "    plt.imshow(np.transpose(grid, (1, 2, 0)))\n",
    "    plt.savefig(f\"generated_images/epoch_{epoch:03d}.png\")\n",
    "    plt.close()\n",
    "\n",
    "# Plot loss curve\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(G_losses, label='Generator Loss')\n",
    "plt.plot(D_losses, label='Discriminator Loss')\n",
    "plt.title(\"WGAN Training Losses\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig(\"wgan_loss_plot.png\")\n",
    "plt.close()\n",
    "\n",
    "# Final comparison\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Real Images\")\n",
    "real_batch = next(iter(trainloader))[0].to(device)\n",
    "real_grid = torchvision.utils.make_grid(real_batch[:64], padding=5, normalize=True)\n",
    "plt.imshow(np.transpose(real_grid.cpu(), (1, 2, 0)))\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Fake Images\")\n",
    "plt.imshow(np.transpose(img_list[-1], (1, 2, 0)))\n",
    "plt.savefig(\"wgan_final_comparison.png\")\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "generative-ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
